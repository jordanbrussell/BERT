{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Tweet_Scraping.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"2kTnVy6AKUtZ"},"source":["# Scraping Data From Twitter\n","Group number 9\n","\n","Group members Jordan Bickelhaupt Evelina Ramoskaite Dave Sawh Andrew Schiek\n","\n","jordanrbickelhaupt@gmail.com evelina.ramoskaite@gmail.com devindrasawh@gmail.com aschiek1@depaul.edu\n","\n"]},{"cell_type":"code","metadata":{"id":"KCQVLJTfKUtg"},"source":["# API Key\n","# T79OGk7rOw7EoKLvlemIrtACE\n","\n","#API Secret Key\n","# Kb9clPlQjsICv6VU6AJPezSEA98qj13yFgzKUq2BSmAyZdk6if\n","\n","#Bearer Token\n","# AAAAAAAAAAAAAAAAAAAAAK0HOwEAAAAAWOu9MKUs1gZLYsSNxDmxBWCwU84%3DA7KbUUblBvzm139nB2z6hdB4v1ioRO7ZzxVhgVdl6tLizJc4OT\n","\n","# Access Token\n","# 1382438548243161089-c7zmGHAu9XRwR1XUUPZ0aM9mLyXVpU\n","\n","# Access Token Secret\n","# A7zNllSD367Vd5EAo95wbmaiNBeT9ucrB3qg849Sl3fVC"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JFt68X2XKUth"},"source":["# Importing libraries\n","import tweepy\n","import csv\n","import re\n","import json\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRA6v5yZKUti"},"source":["def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase, date_since=\"2021-05-22\", date_end=\"2021-05-23\"):\n","    \"\"\"Scrapes twitter for tweets given a data and desired hashtag, then outputs the data into a csv file\"\"\"\n","    # create authentication for accessing Twitter\n","    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n","    auth.set_access_token(access_token, access_token_secret)\n","\n","    # initialize Tweepy API\n","    api = tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n","\n","\n","\n","    # open the spreadsheet we will write to\n","    with open('hastag%s.csv'%(spreadsheetName),'w',encoding='utf-8') as file:\n","        w = csv.writer(file)\n","\n","        # write header row to spreadsheet\n","        w.writerow(['timestamp', 'tweet_text','all_hashtags','retweet_count', 'tweet_created_at',' username', 'followers_count'])\n","\n","\n","        # for each tweet matching our hashtags, write relevant info to the spreadsheet\n","        backoff_counter = 1\n","        while True:\n","            try:\n","                for tweet in tweepy.Cursor(api.search,q=hashtag_phrase + ' -filter:retweets', \\\n","                                           lang=\"en\",since= date_since,until=date_end, tweet_mode='extended').items(100000): # iterating over first 100,000 tweets\n","                    w.writerow([tweet.created_at,\n","                                tweet.full_text.replace('\\n', ' ').encode('utf-8').decode('utf-8'),                       # tweet text\n","                                [e['text'] for e in tweet._json['entities']['hashtags']],                 # hashtags\n","                                tweet.retweet_count,                                                      # retweet count\n","                                tweet.created_at,                                                         # tweet created at\n","                                tweet.user.screen_name.encode('utf-8').decode('utf-8'),                                   # username\n","                                tweet.user.followers_count],                                              # user followers\n","                                )\n","                break\n","            except tweepy.TweepError as e:\n","                print(e.reason)\n","                sleep(60*backoff_counter)\n","                backoff_counter += 1\n","                continue\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ihhv3hn1KUtj"},"source":["# Inputing the access tokens and asking the user for the hashtag they wish to search\n","spreadsheetName= input('filename hashtag ______:  ')               # enter desired name for output file\n","consumer_key = 'T79OGk7rOw7EoKLvlemIrtACE'\n","consumer_secret = 'Kb9clPlQjsICv6VU6AJPezSEA98qj13yFgzKUq2BSmAyZdk6if'\n","access_token = '1382438548243161089-c7zmGHAu9XRwR1XUUPZ0aM9mLyXVpU'\n","access_token_secret = 'A7zNllSD367Vd5EAo95wbmaiNBeT9ucrB3qg849Sl3fVC'\n","\n","hashtag_phrase = input('Stock Hashtag: ')           # enter stock hashtag\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KO7S6NuTKUtk"},"source":["\n","if __name__ == '__main__':\n","    search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)"],"execution_count":null,"outputs":[]}]}